import java.io.*;
import java.util.ArrayList;
import java.util.List;

public class AdaBoost implements Classifier {
	
	// To be returned by the public methods for author and description
	private String author = "Helen and Aditya";
    private String description = "An adaBoost classifier using decision stump
    							  as the weak learner";

    // An array of example weights
    private double[] weights;

    // An array of all the hypotheses
    private int[] hypotheses;

    // An array of alphas
    private double[] alpha;

    // Number of rounds - NO CLUE HOW TO DETERMINE IT AS OF NOW
    private rounds;

    // Decision stump array instance variable
    private DecisionTree[] stumps;

    // Predictions for stump per attribute
    boolean[][] validatePrediction;

    // Constructor
    // PROVIDE GOOD DESCRIPTION HERE
    public AdaBoost(DataSet d)
    {
    	// Assign number of weights from training examples
    	weights = new double[d.numTrainExs];

        // Initialize the weights to 1 / number of training examples
        for (int i = 0; i < d.numTrainExs; i++)
            weights[i] = 1.0 / numTrainExs;

        // Initialize weak learner decision stump array, one for each attribute
        stumps = new DecisionTree[d.numAttrs];

        validatePrediction = new boolean[d.numAttrs][d.numTrainExs];

        // Get classification for each attribute
        for (int i = 0; i < d.numAttrs; i++)
        {
            stumps[i] = new DecisionTree(d, i);

            // Training examples that have wrong predictions for current
            // attribute
            for (int j = 0; j < d.numTrainExs; j++)
            {
                validatePrediction[i][j] = 
                (stumps[i].predict(d.trainEx[j]) == d.trainLabel[j]);
            }        
        }

    	// Assign value to number of rounds
    	rounds = 100;

    	// Initialize array for hypotheses
    	hypotheses = new int[rounds];

    	// Initialize array for alpha
    	alpha = new double[rounds];

    	// Iterate the entire process for the number of rounds
    	for (int counter = 0; counter < rounds; counter++)
    	{
            double minError = Double.POSITIVE_INFINITY;
            int minAttr = -1;

    		// Get minimum error
            for (int i = 0; i < d.numAttrs; i++)
            {
                double currentError = 0.0;

                for (int j = 0; j < d.numTrainExs; j++)
                {
                    if (validatePrediction[i][j])
                        currentError += 0;
                    else
                        currentError += weights[j];

                    if (currentError < minError)
                    {
                        minError = currentError;
                        minAttr = i;
                    }
                }
            }

            // Set hypothesis for current iteration
            hypotheses[counter] = minAttr;

            // Update alpha
            alpha[counter] = 0.5 * Math.log((1 - minError) / minError);

            // Sum of weights for normalization
            double sumWeights = 0.0;

            // Update weights
            for (int j = 0; j < numTrainExs; j++)
            {
                if (validatePrediction[minAttr][j])
                    weights[j] *= Math.pow(Math.E, -alpha[counter]);
                else
                    weights[j] *= Math.pow(Math.E, alpha[counter]);

                // Calulate sum of weights for normalization
                sumWeights += weights[j];
            }

            // Normalize
            for (int j = 0; j < numTrainExs; j++)
                weights[j] /= sumWeights;
    	}
    }

     /** Prediction based on the decision tree generated by constructor */
    public int predict(int[] ex) {
        // TO DO
    }

    /** This method returns a description of the learning algorithm. */
    public String algorithmDescription() {
        return description;
    }

    /** This method returns the author of this program. */
    public String author() {
        return author;
    }
}