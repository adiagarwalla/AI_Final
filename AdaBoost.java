import java.io.*;
import java.util.ArrayList;
import java.util.List;

public class AdaBoost implements Classifier {
	
    // To be returned by the public methods for author and description
    private String author = "Helen and Aditya";
    private String description = "An adaBoost classifier using decision stump as the weak learner";
    
    // An array of example weights
    private double[] weights;

    // An array of all the hypotheses in the form of decision stumps
    private DecisionTree[] hypotheses;

    // An array of alphas
    private double[] alpha;

    // The two classifications
    private final int P = 0;
    private final int N = 1;

    // Number of rounds -- set through command line for systematic experiments
    private int rounds;

    // Predictions for stump per attribute
    boolean[][] validatePrediction;

    // Constructor
    // PROVIDE GOOD DESCRIPTION HERE
    public AdaBoost(DataSet d, int rounds){
	    this.rounds = rounds;

    	// Assign number of weights from training examples
    	weights = new double[d.numTrainExs];

        // Initialize the weights to 1 / number of training examples
        for (int i = 0; i < d.numTrainExs; i++)
            weights[i] = 1.0 / d.numTrainExs;

        validatePrediction = new boolean[d.numAttrs][d.numTrainExs];

        // Get classification for each attribute
        for (int i = 0; i < d.numAttrs; i++)
        {
            DecisionTree stump = new DecisionTree(d, i);

            // Training examples that have wrong predictions for current
            // attribute
            for (int j = 0; j < d.numTrainExs; j++)
            {
                validatePrediction[i][j] = 
                (stump.predict(d.trainEx[j]) == d.trainLabel[j]);
            }        
        }

        // Print validatePrediction
        for (int i = 0; i < d.numAttrs; i++)
        {
            for (int j = 0; j < d.numTrainExs; j++)
                System.out.print(validatePrediction[i][j] + " ");

            System.out.println();
        }

    	// Initialize array for hypotheses
    	hypotheses = new DecisionTree[rounds];

    	// Initialize array for alpha
    	alpha = new double[rounds];

    	// Iterate the entire process for the number of rounds
    	for (int counter = 0; counter < rounds; counter++)
        {
            double minError = Double.POSITIVE_INFINITY;
            int minAttr = -1;

    		// Get minimum error
            for (int i = 0; i < d.numAttrs; i++)
            {
                double currentError = 0.0;
		
                for (int j = 0; j < d.numTrainExs; j++)
                {
                    if (!validatePrediction[i][j])
                        currentError += weights[j];
                }
		
                if (currentError < minError){
        		    minError = currentError;
        		    minAttr = i;
        		}
            }

            // Set hypothesis for current iteration
            hypotheses[counter] = new DecisionTree(d, minAttr);

            // Set alpha
            alpha[counter] = 0.5 * Math.log((1 - minError) / minError);

            // Sum of weights for normalization
            double sumWeights = 0.0;

            // Update weights
            for (int j = 0; j < d.numTrainExs; j++)
            {
		        if (validatePrediction[minAttr][j])
                    weights[j] *= Math.pow(Math.E, -alpha[counter]);
                else
                    weights[j] *= Math.pow(Math.E, alpha[counter]);
		
                // Calulate sum of weights for normalization
                sumWeights += weights[j];
            }

            // Normalize
            for (int j = 0; j < d.numTrainExs; j++)
                weights[j] /= sumWeights;
    	}
    }
    
    /** Prediction based on the decision tree generated by constructor */
    public int predict(int[] ex) {
    	double p = 0;
    	double n = 0;

    	for (int i = 0; i < rounds; i++) 
        {
    	    if (hypotheses[i].predict(ex) == P) 
                p += alpha[i];
    	    else 
                n += alpha[i];
    	}

    	return p > n ? P : N;
    }

    /** This method returns a description of the learning algorithm. */
    public String algorithmDescription() {
        return description;
    }

    /** This method returns the author of this program. */
    public String author() {
        return author;
    }

    /** A simple main for testing this algorithm.  This main reads a
     * filestem from the command line, runs the learning algorithm on
     * this dataset, and prints the test predictions to filestem.testout.
     */
    public static void main(String argv[])
    throws FileNotFoundException, IOException 
    {
        if (argv.length < 1) 
        {
            System.err.println("argument: filestem");
            return;
        }

        String filestem = argv[0];

        DataSet d = new DiscreteDataSet(filestem);

        Classifier c = new AdaBoost(d, 100);

        d.printTestPredictions(c, filestem);
    }
}